# ML-Stroke-Prediction
Predictive modeling project using machine learning to identify stroke risk based on health data. Implements logistic regression, decision trees, and random forests with evaluation through ROC-AUC and precision-recall metrics.

---

## Project Overview

Utilizing a dataset comprising several features like age, hypertension status, heart disease presence, and more, the project applies advanced binary classification methods to determine the likelihood of patients experiencing a stroke. The primary goal is to identify key risk factors and predict stroke occurrence, which can help in preventive health management.

## Features

- **Data Preprocessing**: Techniques such as outlier detection, feature selection, and handling of imbalanced data.
- **Exploratory Data Analysis (EDA)**: Visualizations and statistical tests to understand the data distribution and relationships between features.
- **Model Development**: Implementation of logistic regression, decision trees, and random forests, including hyperparameter tuning and model optimization.
- **Evaluation Metrics**: Utilization of confusion matrix, ROC-AUC, precision-recall curves, and other relevant metrics to assess model performance.

## Objectives

- To develop predictive models that can accurately identify individuals at high risk of stroke.
- To analyze the influence of various factors such as age, hypertension, and smoking status on stroke likelihood.
- To enhance the predictive accuracy using machine learning optimizations like feature engineering and model tuning.

## Tools and Technologies

- **Python**: Main programming language used for data analysis and model building.
- **Scikit-Learn and StatsModels**: Libraries for implementing machine learning models.
- **Pandas and NumPy**: For data manipulation and numerical operations.
- **Matplotlib, Seaborn, and Plotly**: For data visualization.
- **SMOTE**: For addressing the challenge of imbalanced datasets.

## Repository Contents

- **Data**: Folder containing the dataset used for model training and testing.
- **Notebooks**: Jupyter notebooks detailing the data preprocessing, exploratory analysis, model building, and evaluation.
- **Scripts**: Python scripts for model training, evaluation, and utility functions.
- **Documentation**: Detailed documentation on the methodologies used and insights derived from the project.

---
